{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework_3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDtskjg0oN1W"
      },
      "source": [
        "\n",
        "Name: Kausik Amancherla\n",
        "\n",
        "Student ID: 002544017"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NtC8mN-c3Sl"
      },
      "source": [
        "!tar -xf 'review_polarity.tar.gz'"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSFmYYZuaE0c"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import os, random,io\n",
        "import numpy as np\n",
        "import nltk\n",
        "#import matplotlib import pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB-LxuNpfIf4"
      },
      "source": [
        "path_2 = '/content/txt_sentoken/neg'\n",
        "path_1 = '/content/txt_sentoken/pos'\n",
        "txt_1 = os.listdir(path_1)\n",
        "txt_2 = os.listdir(path_2)"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSdNzS3Wf5N6"
      },
      "source": [
        "positive = []\n",
        "negative = []\n",
        "mix = []\n",
        "\n",
        "for f in txt_1 :\n",
        "  positive.append(io.open(os.path.join(path_1,f), 'r').read())\n",
        "\n",
        "for f in txt_2 :\n",
        "  negative.append(io.open(os.path.join(path_2,f), 'r').read())"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK4nkBolgAxa"
      },
      "source": [
        "mix = positive+negative"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1F4NIFa0gBiR"
      },
      "source": [
        "dataframe_positive = pd.DataFrame(positive,columns =['data'])\n",
        "dataframe_positive['label'] = 'Positive'\n",
        "\n",
        "dataframe_negative = pd.DataFrame(negative,columns =['data'])\n",
        "dataframe_negative['label'] = 'Negative'\n",
        "\n",
        "dataframe_mix = pd.concat([dataframe_positive,dataframe_negative])"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tE-I4_mdXSi"
      },
      "source": [
        "1. Using NLTK tokenize all documents, separated by polarity, remove stop words, and list\n",
        "the top 20 most frequent tokens (and their counts) for the positive reviews, and the top\n",
        "20 most frequent tokens (and their counts). What kind of things do you notice are\n",
        "different between the two sets? (30 points)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8p3LljkIgmuP",
        "outputId": "99aba874-bdd1-42f4-fa18-2761464e7bc9"
      },
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords  \n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords') \n",
        "nltk.download('wordnet')\n"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hzk0b_MYpm7x"
      },
      "source": [
        "allpositive = \"\".join(map(str,dataframe_positive['data']))\n",
        "allnegative = \"\".join(map(str,dataframe_negative['data']))"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTh-PaAju6Y6"
      },
      "source": [
        "tok_pos = nltk.word_tokenize(allpositive.lower())\n",
        "tok_neg = nltk.word_tokenize(allnegative.lower())  \n"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0kIaO-BmJin"
      },
      "source": [
        "stop_words = set(stopwords.words('english'))  \n",
        "\n",
        "after_chillar_pos =[]\n",
        "for x in tok_pos:\n",
        "  if not x in stop_words and x.isalpha():\n",
        "    after_chillar_pos.append(x)\n",
        "\n",
        "after_chillar_neg =[]\n",
        "for x in tok_neg:\n",
        "  if not x in stop_words and x.isalpha():\n",
        "    after_chillar_neg.append(x)\n",
        "\n"
      ],
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GswLcFaD7GHP"
      },
      "source": [
        "freq1 = nltk.FreqDist(after_chillar_pos)\n",
        "pos_freq = freq1.most_common(20)\n",
        "freq2 = nltk.FreqDist(after_chillar_neg)\n",
        "neg_freq = freq2.most_common(20)\n"
      ],
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2BxHbl772vl",
        "outputId": "d86a81b6-90d1-4ff5-fa44-4b18bda7ad33"
      },
      "source": [
        "print('Top 20 most frequent tokens for the positive reviews:')\n",
        "for x in range(len(pos_freq)):\n",
        "    print(pos_freq[x][0],'=',pos_freq[x][1])\n",
        "  "
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 20 most frequent tokens for the positive reviews:\n",
            "film = 5186\n",
            "one = 2943\n",
            "movie = 2497\n",
            "like = 1713\n",
            "story = 1231\n",
            "also = 1200\n",
            "good = 1190\n",
            "even = 1175\n",
            "time = 1171\n",
            "would = 1079\n",
            "character = 1067\n",
            "much = 1026\n",
            "life = 992\n",
            "characters = 985\n",
            "first = 964\n",
            "two = 960\n",
            "well = 957\n",
            "see = 955\n",
            "way = 915\n",
            "get = 886\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paH6dh_49KXj",
        "outputId": "9ff17a5e-6bae-4531-e8e2-bce21912428e"
      },
      "source": [
        "print('Top 20 most frequent tokens for the negative reviews:')\n",
        "for x in range(len(neg_freq)):\n",
        "    print(neg_freq[x][0],'=',neg_freq[x][1])"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 20 most frequent tokens for the negative reviews:\n",
            "film = 4257\n",
            "movie = 3174\n",
            "one = 2637\n",
            "like = 1832\n",
            "even = 1381\n",
            "would = 1185\n",
            "good = 1126\n",
            "time = 1111\n",
            "get = 1039\n",
            "bad = 1019\n",
            "much = 998\n",
            "character = 929\n",
            "story = 914\n",
            "could = 898\n",
            "plot = 879\n",
            "characters = 873\n",
            "two = 867\n",
            "make = 819\n",
            "first = 805\n",
            "really = 781\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpsjGgEvdf3p"
      },
      "source": [
        "2. Using the code from previous lectures, build 3 polarity classifiers using the following\n",
        "parameters (20 points). Note: just train the models.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Maya4Vc-mUX"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DwhmSTiMixE"
      },
      "source": [
        "2. Using the code from previous lectures, build 3 polarity classifiers using the following\n",
        "parameters (20 points). Note: just train the models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbx3qUwhc-6J"
      },
      "source": [
        "a) For training: use 50% of the positive dataset and 70% of the negative dataset. For\n",
        "your model use: NaiveBayes with the TF-IDF vectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-bUhsotc-6W"
      },
      "source": [
        "b) For training: use 50% of the negative dataset and 70% of the positive dataset. For\n",
        "your model use: NaiveBayes with the TF-IDF vectorizer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBQn1Zpmc-6W"
      },
      "source": [
        "c) For training: use 25% of the negative dataset and 25% of the positive dataset. For\n",
        "your model use: SVM with the TF-IDF vectorizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTjoqoVtMjXk"
      },
      "source": [
        "def Model_Creation(Algorithm,Vectorization,Training):\n",
        "   model = make_pipeline(Vectorization(),Algorithm()) \n",
        "   model = model.fit(Training.data,Training.label)\n",
        "   return model"
      ],
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_psBXZWMuFK"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(dataframe_positive.data,dataframe_positive.label,test_size=0.50,random_state=12345)\n",
        "\n",
        "Naive_Training_data_1,Naive_Testing_data_1 = train_test_split(dataframe_positive,test_size=0.50,random_state=12345)\n",
        "Naive_Training_data_2,Naive_Testing_data_2 = train_test_split(dataframe_negative,test_size=0.30,random_state=12345)\n",
        "\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "NTV = pd.concat([Naive_Training_data_1,Naive_Training_data_2])\n",
        "NTV_test = pd.concat([Naive_Testing_data_1,Naive_Testing_data_2])\n"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_15oeEENMK4"
      },
      "source": [
        "NV_model_1=Model_Creation(MultinomialNB,TfidfVectorizer,NTV) #a"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YrWqPnGTrP_"
      },
      "source": [
        "Naive_Training_data_3,Naive_Testing_data_3 = train_test_split(dataframe_positive,test_size=0.30,random_state=12345)\n",
        "\n",
        "Naive_Training_data_4,Naive_Testing_data_4 = train_test_split(dataframe_negative,test_size=0.50,random_state=12345)\n",
        "\n",
        "NTV_b = pd.concat([Naive_Training_data_3,Naive_Training_data_4])\n",
        "NTV_test_b = pd.concat([Naive_Testing_data_3,Naive_Testing_data_4])"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V18jlrjBY0QD"
      },
      "source": [
        "NV_model_2=Model_Creation(MultinomialNB,TfidfVectorizer,NTV_b) #b"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLhqr4r5ZJ2p"
      },
      "source": [
        "Naive_Training_data_5,Naive_Testing_data_5 = train_test_split(dataframe_positive,test_size=0.75,random_state=12345)\n",
        "\n",
        "Naive_Training_data_6,Naive_Testing_data_6 = train_test_split(dataframe_negative,test_size=0.75,random_state=12345)\n",
        "\n",
        "NTV_c = pd.concat([Naive_Training_data_5,Naive_Training_data_6])\n",
        "NTV_test_c = pd.concat([Naive_Testing_data_5,Naive_Testing_data_6])"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmwLwEPkZhVn"
      },
      "source": [
        "NV_model_3=Model_Creation(SVC,TfidfVectorizer,NTV_c) #c"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCJoTd6sdu4X"
      },
      "source": [
        "3. Using the models from question 2, evaluate them on their individual rest of the dataset.a) 50% positive and 30% negative, b) 50% negative and 30% positive and c) 75% negative and 75% positive.. Calculate and show ONLY the following metrics for\n",
        "each model: Accuracy, Precision, Recall, Macro F1-score. (15 points)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBGa31KnZ2v_"
      },
      "source": [
        "label_1=NV_model_1.predict(NTV_test.data)\n",
        "label_2=NV_model_2.predict(NTV_test_b.data)\n",
        "label_3=NV_model_3.predict(NTV_test_c.data)"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsoZzSsWaIPR"
      },
      "source": [
        "import sklearn\n",
        "\n",
        "f1Score1 = []\n",
        "accuracy1 = []\n",
        "precision1 = []\n",
        "recall1 = []\n",
        "\n",
        "columns=['Model_Name','Vectorizer','Accuracy','Precision','Recall','Macro_F1-score']\n",
        "\n",
        "def scorefunction(label,testdata):\n",
        "  temp= sklearn.metrics.f1_score(label,testdata.label,average='macro')\n",
        "  temp2 = sklearn.metrics.accuracy_score(testdata.label,label)\n",
        "  temp3 = sklearn.metrics.precision_score(testdata.label,label,pos_label = \"Positive\")\n",
        "  temp4 = sklearn.metrics.recall_score(testdata.label,label,pos_label = \"Positive\")\n",
        "  \n",
        "  f1Score1.append(temp)\n",
        "  accuracy1.append(temp2)\n",
        "  precision1.append(temp3)\n",
        "  recall1.append(temp4)"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g41OICN2aivx"
      },
      "source": [
        "scorefunction(label_1,NTV_test)\n",
        "scorefunction(label_2,NTV_test_b)\n",
        "scorefunction(label_3,NTV_test_c)"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zY6vRJewcTnV",
        "outputId": "b34044e0-f72b-4128-e010-14dd2eb3d006"
      },
      "source": [
        "f1Score1"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.28165913567373424, 0.2727272727272727, 0.7533052649545904]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAOWq2S_bBZE"
      },
      "source": [
        "columns=['Model_Name','Vectorizer','Accuracy','Precision','Recall','Macro_F1-score']\n",
        "Modelnames = ['Naive_Bayes','Naive_Bayes','Support_Vector_Machines']\n",
        "vec = ['TFIDF','TFIDF','TFIDF']\n",
        "performace = pd.DataFrame()\n",
        "performace['Model_Name'] = Modelnames\n",
        "performace['Vectorizer'] = vec\n",
        "performace['Accuracy'] = accuracy1\n",
        "performace['Precision'] = precision1\n",
        "performace['Recall'] = recall1\n",
        "performace['Macro_F1-score'] = f1Score1"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "UVhkOI5hbeWY",
        "outputId": "323e8857-f06b-4f35-ea28-4a30e06d63a7"
      },
      "source": [
        "performace"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_Name</th>\n",
              "      <th>Vectorizer</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Macro_F1-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Naive_Bayes</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>0.380000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.281659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Naive_Bayes</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.272727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Support_Vector_Machines</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>0.753333</td>\n",
              "      <td>0.748042</td>\n",
              "      <td>0.764</td>\n",
              "      <td>0.753305</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Model_Name Vectorizer  ...  Recall  Macro_F1-score\n",
              "0              Naive_Bayes      TFIDF  ...   0.008        0.281659\n",
              "1              Naive_Bayes      TFIDF  ...   1.000        0.272727\n",
              "2  Support_Vector_Machines      TFIDF  ...   0.764        0.753305\n",
              "\n",
              "[3 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyOOdoEVdunn"
      },
      "source": [
        "4) Using the model performance metrics from question 3, answer the following\n",
        "questions. Please provide logical and intuitive rationale for your answers, simple\n",
        "answers like: because it has the best score, will not be sufficient. (40 points):\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "jn2w_SWrdkOX",
        "outputId": "4a0b03fe-8661-4265-f559-bf923df950d2"
      },
      "source": [
        "performace.sort_values(by = 'Accuracy',ascending=False)"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_Name</th>\n",
              "      <th>Vectorizer</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Macro_F1-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Support_Vector_Machines</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>0.753333</td>\n",
              "      <td>0.748042</td>\n",
              "      <td>0.764</td>\n",
              "      <td>0.753305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Naive_Bayes</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>0.380000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.281659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Naive_Bayes</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.272727</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Model_Name Vectorizer  ...  Recall  Macro_F1-score\n",
              "2  Support_Vector_Machines      TFIDF  ...   0.764        0.753305\n",
              "0              Naive_Bayes      TFIDF  ...   0.008        0.281659\n",
              "1              Naive_Bayes      TFIDF  ...   1.000        0.272727\n",
              "\n",
              "[3 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MiFsYpudueG"
      },
      "source": [
        "a) What is the best performing model?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnGOd_WXdr3d"
      },
      "source": [
        "Best Model : Support Vector Machines with TFIDF Vectorizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAk0izKHduNX"
      },
      "source": [
        "b) Why do you think this is the best performing model?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dte9EveXd0Yh"
      },
      "source": [
        "Metric: Accuracy\n",
        "\n",
        "Why: Both positive and negative training datasets are equally distrubuted  1000 files each.As they are balanced, accuracy is a correct metric in comparing which model is the best."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96ztbRlkef31"
      },
      "source": [
        "c) How does class imbalance play in determining polarity?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78Gsd2cbeF55"
      },
      "source": [
        "Class imbalance plays a significant part in determining polarity when the dataset of positive and negative are not equally distrubuted. For example if we dataset of 80% postive and 20% negative dataset, the model is trained to look at positive data more.So this model thus predicts more test data as positive than negative.\n",
        "This is because it has seen more words in positive dataset and thus Associaties everything with it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7u9mkI9begPy"
      },
      "source": [
        "d) Do you think either more data or a better model is a better approach for this\n",
        "kind of task?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9-zD0VmfAzQ"
      },
      "source": [
        "A better model is a better approach for this as more data generally leads to overfitting.Morover there are limited number of words that you keep seeing in the postive and negative datasets.So more training data doesn't really matter when training the model\n",
        "But a better model helps as the way in which the model evalutes these limited words plays a significant part.Example SVM model looks for unique words instead of most repetitive words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbK7B4GLep1j"
      },
      "source": [
        "5) Using NLTK and VADER, calculate the sentiment score for all documents in the\n",
        "positive polarity. Calculate the polarity threshold needed (and reasonable) to have the\n",
        "majority of the document labels match. Do the same for the negative class. Provide the\n",
        "threshold needed, the reason why you think this threshold is reasonable, and the\n",
        "accuracy percentage (how many documents are correctly labeled using this threshold).\n",
        "(45 points):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PD5r3d8kkoI"
      },
      "source": [
        "#from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
        "\n",
        "#sia = SIA()\n",
        "\n",
        "#dataframe_positive['neg'] = dataframe_positive['reviews'].apply(lambda x:sia.polarity_scores(x)['neg'])\n",
        "#dataframe_positive['neu'] =dataframe_positive['reviews'].apply(lambda x:sia.polarity_scores(x)['neu'])\n",
        "#dataframe_positive['pos'] = dataframe_positive['reviews'].apply(lambda x:sia.polarity_scores(x)['pos'])\n",
        "#dataframe_positive['compound'] = dataframe_positive['reviews'].apply(lambda x:sia.polarity_scores(x)['compound'])"
      ],
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9Uf3JWperL1"
      },
      "source": [
        "**Bonus (40 points): Repeat questions 2,3 and 4 removing all stopwords. Answer the\n",
        "following questions: Did this change the results in any way? Why do you think so?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_itKeHUb7-d"
      },
      "source": [
        "#removing the stop words from the dataframe\n",
        "dataframe_positive['No_Stop'] = dataframe_positive['data'].apply(lambda x: ' '.join([item for item in x.split() if item not in stop_words]))\n",
        "dataframe_negative['No_Stop'] = dataframe_negative['data'].apply(lambda x: ' '.join([item for item in x.split() if item not in stop_words]))"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKt7PSzohgsS"
      },
      "source": [
        "2. Using the code from previous lectures, build 3 polarity classifiers using the following\n",
        "parameters (20 points). Note: just train the models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezWYWCgahgsf"
      },
      "source": [
        "a) For training: use 50% of the positive dataset and 70% of the negative dataset. For\n",
        "your model use: NaiveBayes with the TF-IDF vectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7cbxLIthgsg"
      },
      "source": [
        "b) For training: use 50% of the negative dataset and 70% of the positive dataset. For\n",
        "your model use: NaiveBayes with the TF-IDF vectorizer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWnBpLkYhgsg"
      },
      "source": [
        "c) For training: use 25% of the negative dataset and 25% of the positive dataset. For\n",
        "your model use: SVM with the TF-IDF vectorizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM8B3AJmhgsg"
      },
      "source": [
        "def Model_Creation(Algorithm,Vectorization,Training):\n",
        "   model = make_pipeline(Vectorization(),Algorithm()) \n",
        "   model = model.fit(Training.data,Training.label)\n",
        "   return model"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Z7mWG5Whgsg"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(dataframe_positive.data,dataframe_positive.label,test_size=0.50,random_state=12345)\n",
        "\n",
        "Naive_Training_data_1,Naive_Testing_data_1 = train_test_split(dataframe_positive,test_size=0.50,random_state=12345)\n",
        "Naive_Training_data_2,Naive_Testing_data_2 = train_test_split(dataframe_negative,test_size=0.30,random_state=12345)\n",
        "\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "NTV = pd.concat([Naive_Training_data_1,Naive_Training_data_2])\n",
        "NTV_test = pd.concat([Naive_Testing_data_1,Naive_Testing_data_2])\n"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZfE0QDChgsh"
      },
      "source": [
        "#a\n",
        "\n",
        "NV_model_1=Model_Creation(MultinomialNB,TfidfVectorizer,NTV) "
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jy-bBG0Qhgsh"
      },
      "source": [
        "Naive_Training_data_3,Naive_Testing_data_3 = train_test_split(dataframe_positive,test_size=0.30,random_state=12345)\n",
        "\n",
        "Naive_Training_data_4,Naive_Testing_data_4 = train_test_split(dataframe_negative,test_size=0.50,random_state=12345)\n",
        "\n",
        "NTV_b = pd.concat([Naive_Training_data_3,Naive_Training_data_4])\n",
        "NTV_test_b = pd.concat([Naive_Testing_data_3,Naive_Testing_data_4])"
      ],
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ay2sIvB3hgsh"
      },
      "source": [
        " #b\n",
        " \n",
        "NV_model_2=Model_Creation(MultinomialNB,TfidfVectorizer,NTV_b)"
      ],
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oLOKm4Ihgsh"
      },
      "source": [
        "Naive_Training_data_5,Naive_Testing_data_5 = train_test_split(dataframe_positive,test_size=0.75,random_state=12345)\n",
        "\n",
        "Naive_Training_data_6,Naive_Testing_data_6 = train_test_split(dataframe_negative,test_size=0.75,random_state=12345)\n",
        "\n",
        "NTV_c = pd.concat([Naive_Training_data_5,Naive_Training_data_6])\n",
        "NTV_test_c = pd.concat([Naive_Testing_data_5,Naive_Testing_data_6])"
      ],
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFCtEAzThgsh"
      },
      "source": [
        "#c\n",
        "\n",
        "NV_model_3=Model_Creation(SVC,TfidfVectorizer,NTV_c) "
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMx_TKwzhgsi"
      },
      "source": [
        "3. Using the models from question 2, evaluate them on their individual rest of the dataset.a) 50% positive and 30% negative, b) 50% negative and 30% positive and c) 75% negative and 75% positive.. Calculate and show ONLY the following metrics for\n",
        "each model: Accuracy, Precision, Recall, Macro F1-score. (15 points)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kf0-Om0Rhgsi"
      },
      "source": [
        "label_1=NV_model_1.predict(NTV_test.No_Stop)\n",
        "label_2=NV_model_2.predict(NTV_test_b.No_Stop)\n",
        "label_3=NV_model_3.predict(NTV_test_c.No_Stop)"
      ],
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aTw7a21hgsi"
      },
      "source": [
        "import sklearn\n",
        "\n",
        "f1Score1 = []\n",
        "accuracy1 = []\n",
        "precision1 = []\n",
        "recall1 = []\n",
        "\n",
        "columns=['Model_Name','Vectorizer','Accuracy','Precision','Recall','Macro_F1-score']\n",
        "\n",
        "def scorefunction(label,testdata):\n",
        "  temp= sklearn.metrics.f1_score(label,testdata.label,average='macro')\n",
        "  temp2 = sklearn.metrics.accuracy_score(testdata.label,label)\n",
        "  temp3 = sklearn.metrics.precision_score(testdata.label,label,pos_label = \"Positive\")\n",
        "  temp4 = sklearn.metrics.recall_score(testdata.label,label,pos_label = \"Positive\")\n",
        "  \n",
        "  f1Score1.append(temp)\n",
        "  accuracy1.append(temp2)\n",
        "  precision1.append(temp3)\n",
        "  recall1.append(temp4)"
      ],
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXm65YIohgsi"
      },
      "source": [
        "scorefunction(label_1,NTV_test)\n",
        "scorefunction(label_2,NTV_test_b)\n",
        "scorefunction(label_3,NTV_test_c)"
      ],
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmgABKs1hgsi",
        "outputId": "dc8b7b93-37f2-4776-9dcf-fac62e9c26a8"
      },
      "source": [
        "f1Score1"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3098903218547233, 0.2926588141230536, 0.3421611068669892]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAiAi6zJhgsj"
      },
      "source": [
        "columns=['Model_Name','Vectorizer','Accuracy','Precision','Recall','Macro_F1-score']\n",
        "Modelnames = ['Naive_Bayes','Naive_Bayes','Support_Vector_Machines']\n",
        "vec = ['TFIDF','TFIDF','TFIDF']\n",
        "performace = pd.DataFrame()\n",
        "performace['Model_Name'] = Modelnames\n",
        "performace['Vectorizer'] = vec\n",
        "performace['Accuracy'] = accuracy1\n",
        "performace['Precision'] = precision1\n",
        "performace['Recall'] = recall1\n",
        "performace['Macro_F1-score'] = f1Score1"
      ],
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "F1WGgiibhgsj",
        "outputId": "6a6b6037-922e-4eab-8047-e8e4439ddc91"
      },
      "source": [
        "performace"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_Name</th>\n",
              "      <th>Vectorizer</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Macro_F1-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Naive_Bayes</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>0.39625</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.034</td>\n",
              "      <td>0.309890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Naive_Bayes</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>0.38625</td>\n",
              "      <td>0.379267</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.292659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Support_Vector_Machines</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>0.50400</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.342161</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Model_Name Vectorizer  ...  Recall  Macro_F1-score\n",
              "0              Naive_Bayes      TFIDF  ...   0.034        0.309890\n",
              "1              Naive_Bayes      TFIDF  ...   1.000        0.292659\n",
              "2  Support_Vector_Machines      TFIDF  ...   0.008        0.342161\n",
              "\n",
              "[3 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31jNCDRmhgsj"
      },
      "source": [
        "4) Using the model performance metrics from question 3, answer the following\n",
        "questions. Please provide logical and intuitive rationale for your answers, simple\n",
        "answers like: because it has the best score, will not be sufficient. (40 points):\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "K7WJYUHthgsj",
        "outputId": "49814faa-0e02-43e8-9183-dfbf4ebaf0bc"
      },
      "source": [
        "performace.sort_values(by = 'Accuracy',ascending=False)"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_Name</th>\n",
              "      <th>Vectorizer</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Macro_F1-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Support_Vector_Machines</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>0.50400</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.342161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Naive_Bayes</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>0.39625</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.034</td>\n",
              "      <td>0.309890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Naive_Bayes</td>\n",
              "      <td>TFIDF</td>\n",
              "      <td>0.38625</td>\n",
              "      <td>0.379267</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.292659</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Model_Name Vectorizer  ...  Recall  Macro_F1-score\n",
              "2  Support_Vector_Machines      TFIDF  ...   0.008        0.342161\n",
              "0              Naive_Bayes      TFIDF  ...   0.034        0.309890\n",
              "1              Naive_Bayes      TFIDF  ...   1.000        0.292659\n",
              "\n",
              "[3 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38Qm8aSthgsk"
      },
      "source": [
        "a) What is the best performing model?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sAAk8gthgsk"
      },
      "source": [
        "Best Model : Support Vector Machines with TFIDF Vectorizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0SaeaMUhgsk"
      },
      "source": [
        "b) Why do you think this is the best performing model?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ybJhqs_hgsk"
      },
      "source": [
        "Metric: Accuracy\n",
        "\n",
        "Why: Both positive and negative training datasets are equally distrubuted  1000 files each.As they are balanced, accuracy is a correct metric in comparing which model is the best."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rbIYiwhhgsk"
      },
      "source": [
        "c) How does class imbalance play in determining polarity?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvtLa52Khgsk"
      },
      "source": [
        "Class imbalance plays a significant part in determining polarity when the dataset of positive and negative are not equally distrubuted. For example if we dataset of 80% postive and 20% negative dataset, the model is trained to look at positive data more.So this model thus predicts more test data as positive than negative.\n",
        "This is because it has seen more words in positive dataset and thus Associaties everything with it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHBHAdqvhgsk"
      },
      "source": [
        "d) Do you think either more data or a better model is a better approach for this\n",
        "kind of task?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtW7SZnEhgsk"
      },
      "source": [
        "A better model is a better approach for this as more data generally leads to overfitting.Morover there are limited number of words that you keep seeing in the postive and negative datasets.So more training data doesn't really matter when training the model\n",
        "But a better model helps as the way in which the model evalutes these limited words plays a significant part.Example SVM model looks for unique words instead of most repetitive words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEd75-s5n9TH"
      },
      "source": [
        "**I dont see much difference in the models as the stop words are pretty common in both the positive and neagtive dataset**"
      ]
    }
  ]
}